{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Spusteni pyspark\n",
    "\n",
    "`pyspark --master yarn --num-executors 2 --executor-memory 4G --packages com.databricks:spark-csv_2.10:1.5.0 --conf spark.ui.port=1<ddmm>`, kde `<ddmm>` je vas den a mesic narozeni, napr. spark.ui.port=10811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uzitecne importy\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Manual Spark SQL](http://spark.apache.org/docs/1.6.0/api/python/pyspark.sql.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Nacteni dat a zakladni explorace\n",
    "\n",
    "Soubor lyrics.txt obsahuje zaznamy o pisnich vcetne textu. Tento soubor nactete jako DataFrame a pri nacteni definujte schema -- viz nize.\n",
    "\n",
    "* format: CSV\n",
    "* cesta `/user/pascepet/data/`\n",
    "* oddelovac je `','`\n",
    "* schema\n",
    "```\n",
    "id – long\n",
    "album – string\n",
    "rok – integer\n",
    "interpret – string\n",
    "zanr – string\n",
    "text – string\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nejprve definice schematu\n",
    "schema_lyrics = StructType([\n",
    "    StructField(\"id\", LongType(), True),\n",
    "    StructField(\"nazev\", StringType(), True),\n",
    "    StructField(\"rok\", IntegerType(), True),\n",
    "    StructField(\"interpret\", StringType(), True),\n",
    "    StructField(\"zanr\", StringType(), True),\n",
    "    StructField(\"text\", StringType(), True)])\n",
    "\n",
    "# nacteni souboru\n",
    "songsDF = sqlContext.read \\\n",
    "    .format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"header\", \"false\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .schema(schema_lyrics)  \\\n",
    "    .load(\"/user/pascepet/data/lyrics.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Nactene DataFrame nakesujte.    \n",
    "`songsDF.cache()`\n",
    "\n",
    "1.2 Vypiste si ukazku dat.    \n",
    "`songsDF.show()`\n",
    "\n",
    "1.3 Zjistete pocet zaznamu (radku) v DataFrame.    \n",
    "`songsDF.count()`\n",
    "\n",
    "1.4 Zjistete, kolik pisni ma jako interpreta Boba Dylana ('bob-dylan').    \n",
    "`songsDF.filter(songsDF.interpret=='bob-dylan').count()`\n",
    "\n",
    "1.5 Zjistete, jaky je nejnizsi a nejvyssi uvedeny rok pisne.    \n",
    "`songsDF.groupBy().min('rok').show()\n",
    "songsDF.groupBy().max('rok').show()`\n",
    "\n",
    "1.6 Zjistete, ktery zanr ma nejvic pisni.    \n",
    "`songs_zanry = songsDF.select('zanr').groupBy('zanr').count().toDF('zanr', 'pocet')\n",
    "songs_zanry.orderBy(songs_zanry.pocet.desc()).show()`    \n",
    "`# nebo songs_zanry.orderBy(F.desc('pocet')).show()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Uprava a cisteni dat\n",
    "\n",
    "2.1 Vyradte vsechny zaznamy, ktere maji uvedeny rok mimo rozmezi 1950--2018. Zjistete, kolik zaznamu v DataFrame zustalo.\n",
    "\n",
    "`songsDF = songsDF.filter('rok>=1950 and rok<=2018')`    \n",
    "`# nebo songsDF.filter((songsDF.rok>=1950) & (songsDF.rok<=2018))`    \n",
    "`songsDF.count()`\n",
    "\n",
    "2.2 Z textu pisne odstrante vsechny znaky ',.:;!?()[]' (obtiznejsi varianta: odstrante vsechny nealfanumericke znaky krome mezer) a text prevedte na mala pismena.\n",
    "\n",
    "`songsDF = songsDF.withColumn('text', F.regexp_replace(songsDF.text, r'[,.;:?!()\\[\\]]', ''))`    \n",
    "`# obtiznejsi varianta: songsDF = songsDF.withColumn('text', F.regexp_replace(songsDF.text, '[^\\w ]', ''))`    \n",
    "`songsDF = songsDF.withColumn('text', F.lower(songsDF.text))`\n",
    "\n",
    "2.3 Pridejte sloupec `slova_poc` obsahujici pocet vsech slov pisne, sloupec `slova_poc_unik` obsahujici pocet vsech unikatnich slov pisne a sloupec `slova_poc_unik2` obsahujici pocet vsech unikatnich slov pisne po vyrazeni stop-words. Slova jsou v textu oddelena carkou. Soubor se stop-words je na HDFS: `/user/pascepet/data/stopwords.txt`.\n",
    "\n",
    "`# pocet vsech slov lze zjistit rovnou - rozdelit na slova a spocitat prvky pole\n",
    "songsDF = songsDF.withColumn('slova_poc', F.size(F.split(songsDF.text, ' ')))`\n",
    "\n",
    "`# pro spocteni unikatnich slov je ale potreba mit sloupec s rozdelenym textem jako mezikrok`    \n",
    "`# rozdelit na slova do noveho sloupce => v poli je array jednotlivych slov\n",
    "songsDF = songsDF.withColumn('text_upr', F.split(songsDF.text, ' '))`    \n",
    "`# pocet unikatnich - abychom mohli pouzit funkce Pythonu, musime definovat uzivatelskou funkci\n",
    "countUniq = F.udf(lambda a: len(set(a)))`    \n",
    "`# ... a tu aplikovat na array ve sloupci\n",
    "songsDF = songsDF.withColumn('slova_poc_unik', countUniq(songsDF.text_upr))`\n",
    "\n",
    "`# pro spocteni unikatnich slov bez stop-words jste nacteme soubor se stop-words\n",
    "stopw = sc.textFile(\"/user/pascepet/data/stopwords.txt\").collect()\n",
    "stopw = set(stopw)`    \n",
    "`# ... a postupujeme stejne jako vyse\n",
    "countUniqNotStop = F.udf(lambda a: len(set(a).difference(stopw)))\n",
    "songsDF = songsDF.withColumn('slova_poc_unik2', countUniqNotStop(songsDF.text_upr))`\n",
    "\n",
    "`songsDF = songsDF.drop('text_upr') # vyhodime sloupec s upravenym textem`\n",
    "\n",
    "\n",
    "2.4 Vysledny DataFrame opet nakesujte.    \n",
    "`songsDF.cache()`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analyticke dotazy\n",
    "\n",
    "3.1 Zjistete pocty pisni podle jednotlivych roku.    \n",
    "`songsDF.groupBy('rok').count().show()`\n",
    "\n",
    "3.2 Zjistete, kolik interpretu ma aspon 500 pisni a kteri to jsou.    \n",
    "`interprets = songsDF.groupBy('interpret').count() \\\n",
    "  .toDF('interpret', 'pocet').filter(\"pocet >= 500\")\n",
    "interprets.show()`\n",
    "\n",
    "3.3 Ktery interpret ma v prumeru nejvice unikatnich slov na jednu pisen? A zmeni se to, pokud se budou pocitat jen unikatni slova bez stop-words? (Obtiznejsi varianta: berte v uvahu jen interprety, kteri maji aspon 50 pisni.)\n",
    "\n",
    "`# ukazka prace s DataFrame pomoci SQL dotazu \n",
    "songsDF.registerTempTable(\"songs\")\n",
    "slova_prum = sqlContext.sql(\"\"\"select interpret, avg(slova_poc_unik) as slova_unik_prum, avg(slova_poc_unik2) as slova_unik2_prum, count(*) as pisne_pocet from songs\n",
    "    group by interpret\"\"\")`\n",
    "    \n",
    "`slova_prum.select('interpret', 'slova_unik_prum').orderBy(F.desc('slova_unik_prum')).show()\n",
    "slova_prum.select('interpret', 'slova_unik2_prum').orderBy(F.desc('slova_unik2_prum')).show()\n",
    "slova_prum.filter('pisne_pocet>=50').orderBy(F.desc('slova_unik_prum')).show()\n",
    "slova_prum.filter('pisne_pocet>=50').orderBy(F.desc('slova_unik2_prum')).show()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Text-mining\n",
    "\n",
    "4.1 Najdete 20 nejcasteji se vyskytujicich slov bez stop-words. (Kazde slovo pocitejte tolikrat, kolikrat je v textu uvedeno.)    \n",
    "`# texty rozdelit na slova`    \n",
    "`# pustit dal jen slova, ktera nepatri do stopwords (stopw je drive nacteny soubor, typ set)`    \n",
    "`# a klasicky word-count s tridenim podle poctu`    \n",
    "`words_top = songsDF.flatMap(lambda r: r[5].split(\" \")) \\\n",
    "    .filter(lambda r: r not in stopw) \\\n",
    "    .map(lambda r: (r, 1)) \\\n",
    "    .reduceByKey(lambda a,b: a+b) \\\n",
    "    .sortBy(lambda r: r[1], False)`\n",
    "    \n",
    "`words_top.take(20)`\n",
    "\n",
    "4.2 Vyberte 3 nejcastejsi slova (krome stop-words) a k DataFrame pridejte tri sloupce s priznaky, zda je v pisni dane slovo aspon jednou uvedeno.    \n",
    "`# priklad pro slova love, like, know\n",
    "songsDF = songsDF.withColumn('is_love', F.when(F.regexp_extract(songsDF.text, r'\\b(love)\\b', 1) == 'love', 1).otherwise(0))\n",
    "songsDF = songsDF.withColumn('is_like', F.when(F.regexp_extract(songsDF.text, r'\\b(like)\\b', 1) == 'like', 1).otherwise(0))\n",
    "songsDF = songsDF.withColumn('is_know', F.when(F.regexp_extract(songsDF.text, r'\\b(know)\\b', 1) == 'know', 1).otherwise(0))`\n",
    "\n",
    "4.3 U interpretu s aspon 500 pisnemi (viz 3.2) zjistete, v jakem podilu jejich pisni se vyskytuji tri vami vybrana nejcastejsi slova.    \n",
    "`interprets_words = interprets.join(songsDF, interprets.interpret==songsDF.interpret) \\\n",
    "    .drop(songsDF.interpret) \\\n",
    "    .select('interpret', 'is_love', 'is_like', 'is_know') \\\n",
    "    .groupBy('interpret') \\\n",
    "    .agg({'is_love':'avg', 'is_like':'avg', 'is_know':'avg'})`\n",
    "\n",
    "`interprets_words.show()`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
